A Helm Package follows a strict structure of files and folders.
The typical structure looks like this\footnote{The test-connection.yaml file can be named anything.
	This is the default name you get in the official template.}:
\dirtree{%
 .1 .
 .2 Chart.yaml.
 .2 README.md.
 .2 templates.
 .3 \_helpers.tpl.
 .3 NOTES.txt.
 .3 tests.
 .4 test-connection.yaml.
 .2  values.yaml.
}

\section{The \enquote{Chart.yaml}}
This is the file defining the metadata of the Helm Chart.
Important fields are the name, description, type, version and appVersion fields.
Most of these are self-explanatory.
Below the special fields will be explained.

\begin{figure}[h]
\begin{minted}[numbers=left, frame=lines,breaklines,breakanywhere,samepage=false]{yaml}
apiVersion: v2
name: matrix-neoboard-widget
description: A whiteboard widget for the Element messenger
type: application
version: 0.1.0
appVersion: "0.0.0"
home: https://github.com/nordeck/matrix-neoboard
\end{minted}
\caption{A simple application Chart.yaml}\label{code:Chart.yaml}
\end{figure}

\subsection{The \emph{appVersion} field}
The appVersion field is referring to the version of the application.
It can be different from the version of the Helm chart which is defined in the version field and is expected to contain the tag of the application's docker image.
Be aware that this is not semver\cite{helmauthorsAppVersionsField} or similar but instead is an opaque string as Helm won't make assumptions about the version of an application.
\subsection{The \emph{maintainers} field}
Another section of the Chart.yaml is the \enquote{maintainers} field which allows you to set the maintainers of the application.
This is not mandatory but useful if you publish this Helm chart to some places.
It is an array which contains a name, an email and a url field and is meant to contain each maintainer that works on the chart.
However, in a company setting it can also be used to just refer to the company instead.

\section{The \enquote{values.yaml}}

\subsection{Images}

The core of every application in Kubernetes is the image used for deploying it.
This is being done in the \enquote{image} section of the  \gls{values}.

\begin{figure}[h]
\begin{minted}[numbers=left, frame=lines,breaklines,breakanywhere,samepage=false]{yaml}
# This sets the container image more information can be found here: https://kubernetes.io/docs/concepts/containers/images/
image:
  repository: nginx
  # This sets the pull policy for images.
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""
# This is for the secretes for pulling an image from a private repository more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
imagePullSecrets: []
\end{minted}
\caption{The \enquote{image} section of the \gls{values}}\label{code:image_section}
\end{figure}

Things to note here are the 3 fields it should contain:

\begin{enumerate}
	\item{
		The repository which sets the image name.
		This would also include things like \enquote{ghcr.io} or other custom repositories used.
	}
	\item{
		The \enquote{pullPolicy} which defines how often it is pulled
		By default this should be \enquote{IfNotPresent}.
		For latest tags it automatically defaults however to \enquote{Always} which, as the name says, will always pull the image when a \Gls{pod} is started.
	}
	\item{
		The \enquote{tag} field defines the value after the colon in a docker image.
		This should stay as an empty string by default since it will be pulled from the chart's \enquote{appVersion} field usually.
		It is meant to allow a consumer to change this if they need to.
	}
\end{enumerate}

Additionally, there is the \enquote{imagePullSecrets} field which allows you to pull from private repositories. For more information on this take a look at \url{https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/}.


\subsection{Service Account}

\begin{figure}[h]
\begin{minted}[numbers=left, frame=lines,breaklines,breakanywhere,samepage=false]{yaml}
# This section builds out the service account more information can be found here: https://kubernetes.io/docs/concepts/security/service-accounts/
serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Automatically mount a ServiceAccount's API credentials?
  automount: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""
\end{minted}
\caption{The \enquote{serviceAccount} section of the \gls{values}}\label{code:service_account_section}
\end{figure}

Service Accounts are required for accessing the resources of the \gls{k8s} cluster itself.
They are scoped accounts to the cluster and require most likely more setup in the templates to actually be useful.
They are commonly used by operators or similar things which listen to or write to resources in the cluster.

\subsection{Service and Ingress}

Ingresses and services usually come in pairs in a production ready application.

\begin{figure}[h]
\begin{minted}[numbers=left, frame=lines,breaklines,breakanywhere,samepage=false]{yaml}
service:
  # This sets the service type more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
  type: ClusterIP
  # This sets the ports more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#field-spec-ports
  port: 80

# This block is for setting up the ingress for more information can be found here: https://kubernetes.io/docs/concepts/services-networking/ingress/
ingress:
  enabled: false
  className: ""
  annotations: {}
  # kubernetes.io/ingress.class: nginx
  # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local
\end{minted}
\caption{The \enquote{service} section and the \enquote{ingress} section of the \gls{values}}\label{code:service_and_ingress_section}
\end{figure}

A service consists of the service type and a port.
The type of service generally will be \enquote{ClusterIP} for production clusters.
However, there are users which might want to prefer \enquote{NodePort} as a type instead of using an Ingress.
Therefor it should be left as an option for users.

For the port on the other hand it depends on the application.
It is only useful to be kept as an option if the container image at runtime allows adjusting it.
This is incredibly useful for \enquote{NodePort} users and should be preferred.
It should default however to the application default to avoid confusion in case an end-user has to debug it.
You can find more information about the service resource in \gls{k8s} at \url{https://kubernetes.io/docs/concepts/services-networking/service}.

\bigskip
The ingress of a Helm chart is used to represent the public access point of an application.
It is used to define one or multiple hosts or subpaths for the application.
They should stay in the same pattern as above since ingresses do depend a lot on the user and their ingress software used.
Additionally this is where the secrets and hosts for the tls certificate attached to the ingress are defined.
It is safe to assume that a \gls{k8s} cluster has means to provide this certificate and therefor should not be part of the application chart itself.

\subsection{Volumes}

Volumes and volume mounts are a way to describe storage in \gls{k8s}.
In terms of a Helm chart there are 2 things to differenciate here.
On the one side we have mandatory storage which an application requires.
Usually this is being named \enquote{persistence} in a Helm chart and takes just the storage size and access modes definition.

For example:

\begin{figure}[h]
\begin{minted}[numbers=left, frame=lines,breaklines,breakanywhere,samepage=false]{yaml}
## Persistence configuration for the media repository function.
## This PVC will be mounted in either Synapse or a media_repo worker.
##
## NB; If you want to be able to scale this, you will have to set the
## accessMode to RWX/ReadWriteMany.
##
persistence:
  enabled: true
  # existingClaim: synapse-data

  # storageClass: "-"
  accessMode: ReadWriteOnce
  size: 10Gi
\end{minted}
\caption{The \enquote{persistence} section of the \gls{values}}\label{code:persistence_section}
\end{figure}

This example defines that the persistence is enabled, does not use an existing \Gls{pvc}.
It also says that we use the \enquote{ReadWriteOnce} access mode meaning only one pod at a time can use it\cite{KubernetesPersistentVolume}.
Last but not least it also defines that the size must be \qty{10}{\giga\byte} for this storage.
The storage class is not set which means the cluster default is used. 
As there can be multiple storage providers it is desirable to have this as an option to allow a user to change this based on their cluster.

Additionally, one could also not set \enquote{size} and \enquote{accessMode} and instead define an existing \gls{pvc}.
That way the underlying \gls{pvc} will not be managed by the chart.
\bigskip

In addition to required storage, there is the option to provide means to add optional user defined storage.
The use for this depends on the application type.
It allows defining the same volumes and volumeMounts definitions as explained\cite{Pods} in the \gls{pod} resource.
As we do not know if in the end the user keeps using our image or forks it, it is a good idea to allow this flexiblity.

Usually it looks something like this example:
\begin{figure}[h]
\begin{minted}[numbers=left, frame=lines,breaklines,breakanywhere,samepage=false]{yaml}
# Additional volumes on the output Deployment definition.
volumes: []
# - name: foo
#   secret:
#     secretName: mysecret
#     optional: false
# Additional volumeMounts on the output Deployment definition.

volumeMounts: []
# - name: foo
#   mountPath: "/etc/foo"
#   readOnly: true
\end{minted}
\caption{The \enquote{volumes} section and the \enquote{volumeMounts} section of the \gls{values}}\label{code:volumes_section}
\end{figure}

\subsection{Security Contexts}
Security Contexts allow changing the rules of the sandbox.
They get as is added to a \Gls{deployment resource}.

\begin{figure}[h]
\begin{minted}[numbers=left, frame=lines,breaklines,breakanywhere,samepage=false]{yaml}
podSecurityContext: {}
# fsGroup: 2000

securityContext: {}
# capabilities:
#   drop:
#   - ALL
# readOnlyRootFilesystem: true
# runAsNonRoot: true
# runAsUser: 1000
\end{minted}
\caption{The security context sections of the \gls{values}}\label{code:security_section}
\end{figure}

Notable things you might want by default but need Docker adjustments are:

\begin{enumerate}
	\item{
		\enquote{readOnlyRootFilesystem} should be enabled.
		This ensures that the system never writes to the temporary filesystem of the pod.
		As a result of this an attacker has a harder time to inject changes into a Pod which would affect the end-user in case a container has been compromised.
		For \enquote{/tmp} you should prefer an \enquote{emptyDir} volume instead.
	}
	\item{
		\enquote{runAsNonRoot}, \enquote{fsGroup} and \enquote{runAsUser} should be set to a non root user.
		This requires docker changes to work.
		This ensures that escaping the sandbox is made harder than it would be with a root user.
	}
	\item{
		\enquote{capabilities} should default to dropping all.
		Ideally these should be tightly scoped.
		Depending on the application common ones are network related and chroot related capabilities with webservers.
	}
\end{enumerate}

\subsection{Resources}
Resources allow \gls{k8s} to better schedule the pods spawned by the application.

I suggest \url{https://home.robusta.dev/blog/stop-using-cpu-limits} for further information on this.

\begin{figure}[h]
\begin{minted}[numbers=left, frame=lines,breaklines,breakanywhere,samepage=false]{yaml}
resources: {}
# We usually recommend not to specify default resources and to leave this as a conscious
# choice for the user. This also increases chances charts run on environments with little
# resources, such as Minikube. If you do want to specify resources, uncomment the following
# lines, adjust them as necessary, and remove the curly braces after 'resources:'.
# limits:
#   cpu: 100m
#   memory: 128Mi
# requests:
#   cpu: 100m
#   memory: 128Mi
\end{minted}
\caption{The \enquote{resources} section of the \gls{values}}\label{code:resources_section}
\end{figure}

\subsection{Probes}
\Gls{k8s} comes with 3 types of probes\cite{ConfigureLivenessReadiness}.
2 of these are commonly used in applications, which are the \enquote{readiness} and the \enquote{liveness} probes.
The \enquote{startup} probe is only used when an application is slow to start and there is a longer waiting time to be expected.

Generally you want to have a health endpoint for this on your application which can be pinged.
Alternatively this also can be a command within the pod.
Usually this also is a command that can be fixed for the Helm chart, but when you do that you should have the timeouts exposed in the \gls{values}.

\subsection{Auto scaling}
Auto scaling is the automation of replication.
For this to work your application needs to support being able to be horizontally scalable.
This means it can run multiple times next to each other without causing inconsistent state or other side effects that may affect a user.

With auto scaling you can make it automatically add pods or remove pods based on the demand which can be measured using CPU or memory usage.
It also allows you to define the maximum and minimum replicas.

\begin{figure}[h]
\begin{minted}[numbers=left, frame=lines,breaklines,breakanywhere,samepage=false]{yaml}
#This section is for setting up autoscaling more information can be found here: https://kubernetes.io/docs/concepts/workloads/autoscaling/
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80
\end{minted}
\caption{The \enquote{autoscaling} section of the \gls{values}}\label{code:autoscaling_section}
\end{figure}

\subsection{Misc}
Apart from well defined sections there are also some ungrouped fields available.

The \enquote{replicaCount} here is the amount of pods being spawned.
Contrary to auto scaling this is a constant amount which \gls{k8s} will always try to aim for.
It however will respect the resource requests and limits.
This means that it might not be able to fulfill the amount if there are not enough resources available on a cluster.

\bigskip
There are also overrides which allow an admin to rename the deployed chart.
This is useful when a chart changed behavior and the calculation of a name changed or when it was migrated from another deployment and namespace of deployment changed which usually is part of the full name.

\bigskip
Annotations and labels are useful for various things like interaction with external tooling.
They are usually deployment specific.

\bigskip

\enquote{nodeSelector}, \enquote{tolerations} and \enquote{affinity} are generally used to influence how an application is being deployed within a cluster.
The nodeSelector value can be used to for example deploy it on a specific node with a specific label.

The tolerations are helping with nodes which have taints.
Taints prevent scheduling unless tolerated.
A common example of a taint is the control plane taint for the control plane nodes of the cluster.
It is usually used to restrict a node for important core tasks of the cluster.

\enquote{Affinity} is another more flexible way for the application to define where it can get scheduled.
A common usecase is to use anti-affinity where pods \enquote{repel} each other so you have redundancy of replicas across the cluster.
You can configure it to not allow a second pod of the same application on the same node.
\begin{figure}[h]
\begin{minted}[numbers=left, frame=lines,breaklines,breakanywhere,samepage=false]{yaml}
# This will set the replicaset count more information can be found here: https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/
replicaCount: 1

# This is to override the chart name.
nameOverride: ""
fullnameOverride: ""

# This is for setting Kubernetes Annotations to a Pod.
# For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/ 
podAnnotations: {}
# This is for setting Kubernetes Labels to a Pod.
# For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
podLabels: {}

nodeSelector: {}

tolerations: []

affinity: {}
\end{minted}
\caption{Values which affect the pods or the deployment but are not in a specific group of things}\label{code:misc_values}
\end{figure}

\section{The \enquote{NOTES.txt}}
The \enquote{NOTES.txt} is a special template file, which allows you to display a message at the end of an installation or upgrade.
It behaves like any other template and is then rendered to the console after a successful deployment.

Commonly it contains information about possible manual tasks you want to take like creating the initial user and also the information where you can reach the deployment.

\begin{figure}[h]
\begin{minted}[numbers=left, frame=lines,breaklines,breakanywhere,samepage=false]{jinja}
1. Get the application URL by running these commands:
{{- if .Values.ingress.enabled }}
{{- range $host := .Values.ingress.hosts }}
  {{- range .paths }}
  http{{ if $.Values.ingress.tls }}s{{ end }}://{{ $host.host }}{{ .path }}
  {{- end }}
{{- end }}
{{- else if contains "NodePort" .Values.service.type }}
  export NODE_PORT=$(kubectl get --namespace {{ .Release.Namespace }} -o jsonpath="{.spec.ports[0].nodePort}" services {{ include "foo.fullname" . }})
  export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath="{.items[0].status.addresses[0].address}")
  echo http://$NODE_IP:$NODE_PORT
{{- else if contains "LoadBalancer" .Values.service.type }}
     NOTE: It may take a few minutes for the LoadBalancer IP to be available.
           You can watch its status by running 'kubectl get --namespace {{ .Release.Namespace }} svc -w {{ include "foo.fullname" . }}'
  export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ include "foo.fullname" . }} --template "{{"{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}"}}")
  echo http://$SERVICE_IP:{{ .Values.service.port }}
{{- else if contains "ClusterIP" .Values.service.type }}
  export POD_NAME=$(kubectl get pods --namespace {{ .Release.Namespace }} -l "app.kubernetes.io/name={{ include "foo.name" . }},app.kubernetes.io/instance={{ .Release.Name }}" -o jsonpath="{.items[0].metadata.name}")
  export CONTAINER_PORT=$(kubectl get pod --namespace {{ .Release.Namespace }} $POD_NAME -o jsonpath="{.spec.containers[0].ports[0].containerPort}")
  echo "Visit http://127.0.0.1:8080 to use your application"
  kubectl --namespace {{ .Release.Namespace }} port-forward $POD_NAME 8080:$CONTAINER_PORT
{{- end }}
\end{minted}
\caption{A standard NOTES.txt}\label{code:NOTES.txt}
\end{figure}

\section{\_helpers.tpl}

The helpers file is a file which does not get rendered.
It however contains a bunch of useful global variables in its generated default form.
Important things like the deployment's full name, common labels for identifying the deployment, name of the service account and a combination of name and version.
Beyond that it can be extended for anything that may be needed to be consistent across multiple templates.